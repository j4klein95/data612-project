---
title: "Data Engineering - Data 612 Project"
author: "Jared 'Jay' Klein"
date: "12/1/2021"
output: html_document
---

```{r}
library(tidyverse)
library(dplyr)
library(pryr)
```

# Use tidyverse coding to import the data into R
```{r}
setwd("D:\\repo\\data612-project\\")

maryland <- read_csv("data\\maryland.csv")
virginia <- read_csv("data\\virginia.csv")
view(virginia)
view(maryland)
```
*Immediately upon importing we can see several features of the dataset. We can see the rows and columns numbers, the datatype of each column, and names associated with each column. These are as follows (pertains to both datasets):*
1. date - the flight date
2. carrier - the unique code assigned to each flight
3. origin - 3-letter Airport abbreviation
4. origin_city - Name of origin city, state
5. orig_st_abr - 2-letter state abbreviation
6. orig_st_name - origin state name
7. destination - 3-letter destination airport abbreviation
8. dest_city - destination city, state
9. dest_st_abr - 2-letter state abbreviation
10. dest_st_name - destination state name. 

*The numerical or data that is read into memory as a double data type are:*
11. q - quarter (1: Jan-March, 2:Apr-June)
12. month - month of sample
13. day - day of the week (1 being Monday, 7 Sunday)
14. cancelled - binary 0 being flight was not cancelled
15. miles - distance travelled
16. fl_count - no idea

# Use and show R coding that presents your table as a data frame and a tibble
```{r}
is_tibble(virginia)
is.data.frame(virginia)
is_tibble(maryland)
is.data.frame(maryland)
```

# Fully explain the data, providing insight regarding all variables of the data table
# Use additional R code covered in class to identify and characterize your data table
```{r}
summary(virginia)
dim(virginia)
```
*With the virginia dataset we have 16 column features and 103216 row samples. 10 of these column features are saved into memory as character datatypes while the other 6 features are treated as doubles. From a technical standpoint, this means that the 10 character features are taking up the most memory. The summaries of column features 'q', 'month', 'day', and 'f1_count' are not of huge significance given that those columns represent values of pertaining to time and dates. A summary look at miles does show rather interesting statistics such as the median travel distance being 474 and the average miles traveled being 615.*
```{r}
summary(maryland)
dim(maryland)
```
*With the Maryland data set we have the same number of column features and with significantly less sample rows. This sort of makes sense given the reality size an d number of airports in Maryland compared to that of Virginia. Interestingly enough the median value of miles traveled is at 611 whereas the mean average miles traveled is at 769, values that are both higher that Virginia.*

# Use tidy R and dplyr functions to modify the data so that it is structured properly for better analysis and processing. Show evidence of new R coding to process and analyze data in the table that we did not cover in class. 

*The Dplyr method 'bind_rows' allows for a very simple concatenation of two data sets. Since both the Virginia and Maryland data sets have identical feature names, the method will very elegantly put the data sets together (one on top of the other.*
```{r}
full_data <- bind_rows(virginia, maryland)
dim(full_data)
```
*Now we can do some analysis on this new table.*
```{r}
dim(full_data)
is_tibble(full_data)
is.data.frame(full_data)
```
*We see that this new data set has the exact same number of column features, as expected, but additional rows. Evidence of a successful concatenation of the two data frames. We also verified that it is a tibble and data frame.*
```{r}
summary(full_data$miles)
```
*Previously, we saw that the summary method gave us some interesting results. When we combine the two we see that the average miles traveled is 657.2 and the median is 500 both values that are between the summary results for this feature in the Maryland and Virginia data sets.*

*One interesting thing we can look at is the new size of the table and how much memory it takes up*

```{r}
object_size(full_data)
object_size(virginia)
object_size(maryland)

object_size(maryland)+ object_size(virginia)
```
*You'll notice that, as expected, the full_data table is significantly larger than the Virginia and Maryland data set. Interestingly enough, when you add the two sizes of Virginia and Maryland you get a bytes size that is larger than the full_data table that is essentially the concatenation of the two tables. Why might this be? Probably some minor stuff on the back-end.*


*Lets see if we can do some more work with the data to enable further analysis. Lets start with giving day, month, and quarters proper names.*
```{r}
full_data <- full_data %>%
  mutate(day = recode(day, `1` = "Monday", `2` = "Tuesday", `3` = "Wednesday", `4` = "Thursday", `5` = "Friday", `6` = "Saturday", `7` = "Sunday")) %>%
  mutate(month = recode(month, `1` = "January", `2` = "February", `3` = "March", `4` = "April", `5` = "May", `6` = "June", `7` = "July", `8` = "August", `9` = "September", `10` = "October", `11` = "November", `12` = "December")) %>%
  mutate(q = recode(q, `1` = "First Quarter", `2` = "Second Quarter", `3` = "Third Quarter", `4` = "Fourth Quarter"))%>%
  rename(quarter = q)

head(full_data)
tail(full_data)
```

*From here we can do a number of different analysis based on day, month, and quarter. Lets keep it high level at quarter for now. How many cancellations occurred in each quarter?*
```{r}
full_data %>%
  group_by(quarter) %>%
  summarise(n = n()) %>%
  rename(total_flights = n)
```


```{r}
full_data %>%
  group_by(quarter)%>%
  count(cancelled)%>%
  filter(cancelled == 1)
```

```{r}
full_data %>%
  group_by(quarter, cancelled)%>%
  summarise(n = n()) %>%
  mutate(percent_of_flights_cancelled = round(100 * n/sum(n), 0)) %>%
  filter(cancelled == 1) %>%
  select(quarter, n, percent_of_flights_cancelled) %>%
  rename(cancelled_flights = n)
```
*So we can see that the first quarter of 2020 had a total of 101814 flights while the second quarter had 39925 flights. Of these flights we see that about 7% of flights (6732 flights) in the first quarter were cancelled while 21% of flights (8366) in the second quarter were cancelled.*

*Staying focused on cancellations, how do cancellations look for each airline? For the sake of trying something new, lets add a column to the data frame based on conditions in the other columns. Specifically, lets add the full name of the airline as a feature to each sample based on the column 'carrier'*
```{r}
full_data %>%
  mutate(airline = case_when(
    carrier == "AA" ~ "American Airlines",
    carrier == "AS" ~ "Alaska Airlines",
    carrier == "B6" ~ "JetBlue",
    carrier == "DL" ~ "Delta Air Lines",
    carrier == "F9" ~ "Frontier Airlines",
    carrier == "G4" ~ "Allegiant Air",
    carrier == "HA" ~ "Hawaiian Airlines",
    carrier == "NK" ~ "Spirit Airlines",
    carrier == "UA" ~ "United Airlines",
    carrier == "WN" ~ "Southwest Airlines"
  )) -> full_data
```

*We now have a column feature with the full Airline name in addition to the carrier code. Lets get a sense for how many flights each airline had.*
```{r}
total_flights_by_airline <- full_data %>%
  group_by(airline) %>%
  summarise(n = n()) %>%
  rename(total_flights = n) %>%
  arrange(desc(total_flights))

total_flights_by_airline
```

*We see that American Airlines had the most flights with Southwest, United, and Delta rounding out the top 4 from the 9 airlines sampled. Lets see how many cancelled flights each airline had.*

```{r}
cancelled_flights_by_airline <- full_data %>%
  group_by(airline, cancelled)%>%
  summarise(n = n()) %>%
  mutate(percent_of_flights_cancelled = round(100 * n/sum(n), 0)) %>%
  filter(cancelled == 1) %>%
  select(airline, n, percent_of_flights_cancelled) %>%
  rename(cancelled_flights = n)

airlines_analysis <- total_flights_by_airline%>%
  full_join(cancelled_flights_by_airline, by="airline")

airlines_analysis
```

*From this analysis table, we can see that our top 3 airlines (in terms of total flights) typically saw 10-13% of their flights cancelled in the first 2 quarters of 2020 with Southwest Airlines at the high end with 13% percent and United Airlines at the lower end with 10%. Of note is Allegiant Airlines which had the 2nd lowest total flights but the highest percent of flights cancelled seeing 31% of those flights cancelled in our time period for 2020. The lowest percent of flights cancelled belongs to Spirit Airline with only 2% of flights being cancelled.*
